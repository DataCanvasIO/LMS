# quantize model to int8 percision

lms quantization --model_name opt-125m --int8 --quantized_model_path quantized_model
